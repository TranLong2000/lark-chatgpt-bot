require('dotenv').config();
const express = require('express');
const { Configuration, OpenAIApi } = require('openai');

const app = express();
app.use(express.json());

const openai = new OpenAIApi(
  new Configuration({ apiKey: process.env.OPENAI_API_KEY })
);

function verifyToken(req) {
  const token = req.headers['x-lark-verify-token'] || '';
  return token === process.env.LARK_VERIFICATION_TOKEN;
}

app.post('/webhook', async (req, res) => {
  // XÃ¡c minh token
  if (!verifyToken(req)) {
    console.log('[âŒ] Invalid verify token:', req.headers['x-lark-verify-token']);
    return res.status(401).send('Invalid verify token');
  }

  // Ping check tá»« Lark (URL Verification)
  if (req.body.type === 'url_verification') {
    return res.send({ challenge: req.body.challenge });
  }

  // Nháº­n tin nháº¯n tá»« ngÆ°á»i dÃ¹ng
  const event = req.body.event;
  if (event && event.message && event.message.content) {
    const userMessage = JSON.parse(event.message.content).text || '';

    try {
      const aiResponse = await openai.createChatCompletion({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'Báº¡n lÃ  má»™t trá»£ lÃ½ áº£o thÃ¢n thiá»‡n.' },
          { role: 'user', content: userMessage }
        ]
      });

      const reply = aiResponse.data.choices[0].message.content;

      // In log thay vÃ¬ reply (vÃ¬ báº¡n chÆ°a tÃ­ch há»£p message reply API)
      console.log(`[ðŸ¤–] Tráº£ lá»i cho "${userMessage}":\n${reply}`);
    } catch (err) {
      console.error('[âŒ] Lá»—i OpenAI:', err.message);
    }
  }

  res.sendStatus(200);
});

const port = process.env.PORT || 8080;
app.listen(port, () => {
  console.log(`ðŸš€ Lark OpenAI bot running on port ${port}`);
});
