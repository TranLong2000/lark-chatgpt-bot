require('dotenv').config();
const express = require('express');
const OpenAI = require('openai');

const app = express();
app.use(express.json());

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// Kiá»ƒm tra verify token
function verifyToken(req) {
  const token = req.headers['x-lark-verify-token'] || '';
  return token === process.env.LARK_VERIFICATION_TOKEN;
}

app.post('/webhook', async (req, res) => {
  // Xá»­ lÃ½ xÃ¡c minh URL
  if (req.body.type === 'url_verification') {
    return res.send({ challenge: req.body.challenge });
  }

  // Kiá»ƒm tra verify token
  if (!verifyToken(req)) {
    console.log('[âŒ] Invalid verify token:', req.headers['x-lark-verify-token']);
    return res.status(401).send('Invalid verify token');
  }

  const event = req.body.event;

  if (event && event.message && event.message.content) {
    const userMessage = JSON.parse(event.message.content).text || '';

    try {
      const aiResponse = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'Báº¡n lÃ  má»™t trá»£ lÃ½ áº£o thÃ¢n thiá»‡n.' },
          { role: 'user', content: userMessage }
        ]
      });

      const reply = aiResponse.choices[0].message.content;
      console.log(`[ðŸ¤–] Tráº£ lá»i cho "${userMessage}":\n${reply}`);
    } catch (err) {
      console.error('[âŒ] Lá»—i OpenAI:', err.message);
    }
  }

  res.sendStatus(200);
});

// âœ… Äá»«ng quÃªn dÃ²ng nÃ y Ä‘á»ƒ bot cháº¡y Ä‘Ãºng cá»•ng
const port = process.env.PORT || 8080;
app.listen(port, () => {
  console.log(`ðŸš€ Lark OpenAI bot running on port ${port}`);
});
